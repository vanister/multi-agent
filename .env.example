# Ollama Configuration

# Base URL for the Ollama API server
# Default: http://localhost:11434
OLLAMA_BASE_URL=http://localhost:11434

# Model name to use for chat completions
# Default: qwen2.5-coder:3b
# Examples for different use cases:
#   - Coding: qwen2.5-coder:3b, codellama:7b
#   - General: llama3:8b, mistral:7b
#   - Research: llama3:70b, mixtral:8x7b
OLLAMA_MODEL=qwen2.5-coder:3b

# Timeout for HTTP requests in milliseconds
# Default: 30000 (30 seconds)
OLLAMA_TIMEOUT_MS=30000

# Agent Configuration

# System role/persona for the agent
# Default: "You are a helpful assistant with access to tools"
# Examples:
#   - Coding: "You are a coding assistant with access to tools"
#   - Research: "You are a research assistant with access to academic tools"
#   - Customer Service: "You are a helpful customer service agent"
AGENT_SYSTEM_ROLE=You are a helpful assistant with access to tools
